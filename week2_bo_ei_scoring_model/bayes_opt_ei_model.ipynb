{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83e3e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel as C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9322cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-9  # numerical stability\n",
    "\n",
    "def _expected_improvement(mu, sigma, y_best, xi=0.0):\n",
    "    sigma_safe = sigma + EPS\n",
    "    improvement = mu - y_best - xi\n",
    "    z = improvement / sigma_safe\n",
    "    ei = improvement * norm.cdf(z) + sigma_safe * norm.pdf(z)\n",
    "    ei[sigma == 0.0] = 0.0\n",
    "    return ei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f5aebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_next_experiment(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    bounds,\n",
    "    n_candidates=1000,\n",
    "    xi=0.0,\n",
    "    random_state=None,\n",
    "    return_all=False\n",
    "):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    cols = list(bounds)\n",
    "    d = len(cols)\n",
    "    if X_train.shape[1] != d:\n",
    "        raise ValueError(\"X_train dimension does not match number of bounds\")\n",
    "\n",
    "    # Step 1: Monte‑Carlo sampling in parameter space\n",
    "    cand_mat = np.column_stack([\n",
    "        rng.uniform(lo, hi, n_candidates) for lo, hi in bounds.values()\n",
    "    ])\n",
    "    cand_df = pd.DataFrame(cand_mat, columns=cols)\n",
    "\n",
    "    # Step 2: Fit Gaussian Process surrogate\n",
    "    kernel = (\n",
    "        C(1.0, (1e-3, 1e3))\n",
    "        * RBF(length_scale=np.ones(d), length_scale_bounds=(1e-2, 1e2))\n",
    "        + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-10, 1e-2))\n",
    "    )\n",
    "    gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=5,\n",
    "    alpha=0.0,\n",
    "    normalize_y=True,\n",
    "    random_state=42,  \n",
    ")\n",
    "    gp.fit(X_train, y_train)\n",
    "    \n",
    "    mu, sigma = gp.predict(cand_mat, return_std=True)\n",
    "\n",
    "    # Step 3: Calculate Expected Improvement (EI)\n",
    "    y_best = y_train.max()\n",
    "    ei = _expected_improvement(mu, sigma, y_best, xi=xi)\n",
    "    best_idx = np.argmax(ei)\n",
    "\n",
    "    best_params = cand_df.iloc[best_idx].to_dict()\n",
    "    best_ei = ei[best_idx]\n",
    "\n",
    "    if return_all:\n",
    "        cand_df = cand_df.assign(mu=mu, sigma=sigma, EI=ei)\n",
    "        return cand_df, best_params, best_ei\n",
    "    return best_params, best_ei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bbbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"data/aryltrifluoromethylation_cytosine.csv\")\n",
    "\n",
    "\n",
    "key_cols = [\n",
    "    \"Cytosine_Conc_(M)\",\n",
    "    \"CF3SO2Na_loading_(equiv.)\",\n",
    "    \"(NH4)2S2O8_loading_(equiv.)\",\n",
    "    \"Residence_time_(min)\",\n",
    "    \"Light_intensity_(W)\",\n",
    "]\n",
    "\n",
    "# random select 10 rows as initial experiment data\n",
    "rng = np.random.default_rng(42)\n",
    "seed_idx = rng.choice(len(df), size=10, replace=False)\n",
    "\n",
    "X_train = df.loc[seed_idx, key_cols].to_numpy()\n",
    "y_train = df.loc[seed_idx, \"Yield_(%)\"].to_numpy() # when get the real y, replace y_train with the real y\n",
    "\n",
    "# define the bounds of the parameter space\n",
    "bounds = {c: (df[c].min(), df[c].max()) for c in key_cols}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1938a5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended next experiment (x₁₁):\n",
      "Cytosine_Conc_(M)                  : 0.05248\n",
      "CF3SO2Na_loading_(equiv.)          : 2.813\n",
      "(NH4)2S2O8_loading_(equiv.)        : 1.291\n",
      "Residence_time_(min)               : 4.796\n",
      "Light_intensity_(W)                : 174.8\n",
      "Predicted mean (mu): 72.83\n",
      "Predicted std dev (sigma): 4.946\n",
      "Expected Improvement (EI): 1.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 推荐 x₁₁，并打印参数、mu、sigma、EI\n",
    "cand_df, best_params, best_ei = propose_next_experiment(\n",
    "    X_train, y_train, bounds, random_state=42, return_all=True\n",
    ")\n",
    "\n",
    "best_idx = cand_df['EI'].idxmax()\n",
    "best_mu = cand_df.loc[best_idx, 'mu']\n",
    "best_sigma = cand_df.loc[best_idx, 'sigma']\n",
    "\n",
    "print(\"recommended next experiment (x₁₁):\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k:<35s}: {v:.4g}\")\n",
    "print(f\"Predicted mean (mu): {best_mu:.4g}\")\n",
    "print(f\"Predicted std dev (sigma): {best_sigma:.4g}\")\n",
    "print(f\"Expected Improvement (EI): {best_ei:.4g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23f43b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - recommended next experiment (x_11):\n",
      "Cytosine_Conc_(M)                  : 0.05248\n",
      "CF3SO2Na_loading_(equiv.)          : 2.813\n",
      "(NH4)2S2O8_loading_(equiv.)        : 1.291\n",
      "Residence_time_(min)               : 4.796\n",
      "Light_intensity_(W)                : 174.8\n",
      "Predicted mean (mu): 72.83\n",
      "Predicted std dev (sigma): 4.946\n",
      "Expected Improvement (EI): 1.076\n",
      "\n",
      "Step 2 - recommended next experiment (x_12):\n",
      "Cytosine_Conc_(M)                  : 0.05325\n",
      "CF3SO2Na_loading_(equiv.)          : 3.066\n",
      "(NH4)2S2O8_loading_(equiv.)        : 1.098\n",
      "Residence_time_(min)               : 8.139\n",
      "Light_intensity_(W)                : 142.4\n",
      "Predicted mean (mu): 44.96\n",
      "Predicted std dev (sigma): 13.73\n",
      "Expected Improvement (EI): 0.06958\n",
      "\n",
      "Step 3 - recommended next experiment (x_13):\n",
      "Cytosine_Conc_(M)                  : 0.06879\n",
      "CF3SO2Na_loading_(equiv.)          : 2.769\n",
      "(NH4)2S2O8_loading_(equiv.)        : 1.198\n",
      "Residence_time_(min)               : 3.119\n",
      "Light_intensity_(W)                : 142.9\n",
      "Predicted mean (mu): 69.65\n",
      "Predicted std dev (sigma): 9.169\n",
      "Expected Improvement (EI): 1.588\n",
      "\n",
      "Step 4 - recommended next experiment (x_14):\n",
      "Cytosine_Conc_(M)                  : 0.063\n",
      "CF3SO2Na_loading_(equiv.)          : 2.531\n",
      "(NH4)2S2O8_loading_(equiv.)        : 0.799\n",
      "Residence_time_(min)               : 5.746\n",
      "Light_intensity_(W)                : 142.5\n",
      "Predicted mean (mu): 75.94\n",
      "Predicted std dev (sigma): 1.258\n",
      "Expected Improvement (EI): 1.105\n",
      "\n",
      "Step 5 - recommended next experiment (x_15):\n",
      "Cytosine_Conc_(M)                  : 0.05479\n",
      "CF3SO2Na_loading_(equiv.)          : 3.069\n",
      "(NH4)2S2O8_loading_(equiv.)        : 0.8451\n",
      "Residence_time_(min)               : 6.249\n",
      "Light_intensity_(W)                : 143.9\n",
      "Predicted mean (mu): 62.46\n",
      "Predicted std dev (sigma): 12.21\n",
      "Expected Improvement (EI): 0.9659\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_steps = 5  # 你想要循环几步，比如5步\n",
    "X_loop = X_train.copy()\n",
    "y_loop = y_train.copy()\n",
    "\n",
    "for i in range(n_steps):\n",
    "    cand_df, next_params, next_ei = propose_next_experiment(\n",
    "        X_loop, y_loop, bounds, random_state=42, return_all=True\n",
    "    )\n",
    "    best_idx = cand_df['EI'].idxmax()\n",
    "    best_mu = cand_df.loc[best_idx, 'mu']\n",
    "    best_sigma = cand_df.loc[best_idx, 'sigma']\n",
    "\n",
    "    print(f\"Step {i+1} - recommended next experiment (x_{11+i}):\")\n",
    "    for k, v in next_params.items():\n",
    "        print(f\"{k:<35s}: {v:.4g}\")\n",
    "    print(f\"Predicted mean (mu): {best_mu:.4g}\")\n",
    "    print(f\"Predicted std dev (sigma): {best_sigma:.4g}\")\n",
    "    print(f\"Expected Improvement (EI): {next_ei:.4g}\\n\")\n",
    "\n",
    "    # if get the real y, replace the real_y with the real y\n",
    "    real_y_list = [75.0, 80.5, 65.2, 70.1, 78.9]\n",
    "    new_x = np.array([list(next_params.values())])\n",
    "    new_y = np.array([real_y])\n",
    "    X_loop = np.vstack([X_loop, new_x])\n",
    "    y_loop = np.append(y_loop, new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0d931f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_array = cand_df['mu'].values\n",
    "sigma_array = cand_df['sigma'].values\n",
    "\n",
    "# Min–Max normalization 到 [0,1]\n",
    "mu_min, mu_max = mu_array.min(), mu_array.max()\n",
    "sigma_min, sigma_max = sigma_array.min(), sigma_array.max()\n",
    "mu_norm = (mu_array - mu_min) / (mu_max - mu_min + 1e-12)\n",
    "sigma_norm = (sigma_array - sigma_min) / (sigma_max - sigma_min + 1e-12)\n",
    "\n",
    "# 打分逻辑\n",
    "score_exploit = mu_norm - sigma_norm     # [-1,1]，正为exploit，负为explore\n",
    "score_explore = sigma_norm - mu_norm     # [-1,1]\n",
    "score_combined = 2*((mu_norm + sigma_norm)/2) - 1  # [-1,1]\n",
    "\n",
    "df_scores = pd.DataFrame({\n",
    "    'mu': mu_array,\n",
    "    'sigma': sigma_array,\n",
    "    'mu_norm': mu_norm,\n",
    "    'sigma_norm': sigma_norm,\n",
    "    'score_exploit': score_exploit,\n",
    "    'score_explore': score_explore,\n",
    "    'score_combined': score_combined\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc769f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
