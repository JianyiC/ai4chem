{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e3e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel as C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9322cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-9\n",
    "\n",
    "def _expected_improvement(mu, sigma, y_best, xi=0.0):\n",
    "    sigma_safe = sigma + EPS\n",
    "    imp        = mu - y_best - xi\n",
    "    z          = imp / sigma_safe\n",
    "    ei         = imp * norm.cdf(z) + sigma_safe * norm.pdf(z)\n",
    "    ei[sigma == 0] = 0.0\n",
    "    return ei\n",
    "\n",
    "def propose_next_experiment(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    bounds,\n",
    "    n_candidates=1000,\n",
    "    xi=0.0,\n",
    "    random_state=None,\n",
    "    return_all=False\n",
    "):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    cols = list(bounds)\n",
    "    d = len(cols)\n",
    "    if X_train.shape[1] != d:\n",
    "        raise ValueError(\"X_train dimension does not match number of bounds\")\n",
    "\n",
    "    # Step 1: Monte‑Carlo sampling in parameter space\n",
    "    cand_mat = np.column_stack([\n",
    "        rng.uniform(lo, hi, n_candidates) for lo, hi in bounds.values()\n",
    "    ])\n",
    "    cand_df = pd.DataFrame(cand_mat, columns=cols)\n",
    "\n",
    "    # Step 2: Fit Gaussian Process surrogate\n",
    "    kernel = (\n",
    "        C(1.0, (1e-3, 1e3))\n",
    "        * RBF(length_scale=np.ones(d), length_scale_bounds=(1e-2, 1e2))\n",
    "        + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-10, 1e-2))\n",
    "    )\n",
    "    gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=5,\n",
    "    alpha=0.0,\n",
    "    normalize_y=True,\n",
    "    random_state=42,  \n",
    ")\n",
    "    gp.fit(X_train, y_train)\n",
    "    \n",
    "    mu, sigma = gp.predict(cand_mat, return_std=True)\n",
    "\n",
    "    # Step 3: Calculate Expected Improvement (EI)\n",
    "    y_best = y_train.max()\n",
    "    ei = _expected_improvement(mu, sigma, y_best, xi=xi)\n",
    "    best_idx = np.argmax(ei)\n",
    "\n",
    "    best_params = cand_df.iloc[best_idx].to_dict()\n",
    "    best_ei = ei[best_idx]\n",
    "\n",
    "    if return_all:\n",
    "        cand_df = cand_df.assign(mu=mu, sigma=sigma, EI=ei)\n",
    "        return cand_df, best_params, best_ei\n",
    "    return best_params, best_ei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45bbbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"data/aryltrifluoromethylation_cytosine.csv\")\n",
    "\n",
    "\n",
    "key_cols = [\n",
    "    \"Cytosine_Conc_(M)\",\n",
    "    \"CF3SO2Na_loading_(equiv.)\",\n",
    "    \"(NH4)2S2O8_loading_(equiv.)\",\n",
    "    \"Residence_time_(min)\",\n",
    "    \"Light_intensity_(W)\",\n",
    "]\n",
    "\n",
    "# random select 10 rows as initial experiment data\n",
    "rng = np.random.default_rng(42)\n",
    "seed_idx = rng.choice(len(df), size=10, replace=False)\n",
    "      \n",
    "X_train = df.loc[seed_idx, key_cols].to_numpy()\n",
    "y_train = df.loc[seed_idx, \"Yield_(%)\"].to_numpy() # when get the real y, replace y_train with the real y\n",
    "\n",
    "# define the bounds of the parameter space\n",
    "bounds = {c: (df[c].min(), df[c].max()) for c in key_cols}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23f43b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_exploit_score(mu, sigma,\n",
    "                          mu_min, mu_max,\n",
    "                          sigma_min, sigma_max):\n",
    "    \"\"\"\n",
    "    mu: predicted mean\n",
    "    sigma: predicted standard deviation\n",
    "    mu_min: minimum predicted mean\n",
    "    mu_max: maximum predicted mean\n",
    "    sigma_min: minimum predicted standard deviation\n",
    "    sigma_max: maximum predicted standard deviation\n",
    "    \"\"\"\n",
    "    mu_norm    = (mu    - mu_min   ) / (mu_max    - mu_min    + 1e-12)\n",
    "    sigma_norm = (sigma - sigma_min) / (sigma_max - sigma_min + 1e-12)\n",
    "    return mu_norm - sigma_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99456fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(x, mode='random', true_func=None):\n",
    "    if mode == 'random':\n",
    "        return float(np.random.uniform(60, 85))   # by default, the yield is between 60 and 85\n",
    "    elif mode == 'manual':\n",
    "        return float(input(f\"Input real yield for {x}: \"))\n",
    "    elif mode == 'simulate' and true_func is not None:\n",
    "        noise = np.random.normal(0, 2)\n",
    "        return float(true_func(x) + noise)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode or missing true_func!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fb0a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "  Cytosine_Conc_(M)               : 0.06181\n",
      "  CF3SO2Na_loading_(equiv.)       : 2.239\n",
      "  (NH4)2S2O8_loading_(equiv.)     : 0.8799\n",
      "  Residence_time_(min)            : 4.774\n",
      "  Light_intensity_(W)             : 174.6\n",
      "  Pred μ=55.82, σ=6.47, EI=1.21\n",
      "  Explore–Exploit score: +0.39\n",
      "  Experiment yield: 80.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 100.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# X_loop: first 10 rows, y_loop: corresponding yields\n",
    "# bounds: dict of (min, max) for each variable\n",
    "X_loop = X_train[:10].copy()\n",
    "y_loop = y_train[:10].copy()\n",
    "\n",
    "cand_df, next_params, next_ei = propose_next_experiment(\n",
    "    X_loop, y_loop, bounds, random_state=42, return_all=True)\n",
    "\n",
    "best_idx   = cand_df['EI'].idxmax()\n",
    "best_mu    = cand_df.loc[best_idx, 'mu']\n",
    "best_sigma = cand_df.loc[best_idx, 'sigma']\n",
    "\n",
    "score = explore_exploit_score(\n",
    "    best_mu, best_sigma,\n",
    "    mu_min=cand_df['mu'].min(),  mu_max=cand_df['mu'].max(),\n",
    "    sigma_min=cand_df['sigma'].min(), sigma_max=cand_df['sigma'].max()\n",
    ")\n",
    "\n",
    "print(\"Step 1\")\n",
    "for k, v in next_params.items():\n",
    "    print(f\"  {k:<32}: {v:.4g}\")\n",
    "print(f\"  Pred μ={best_mu:.2f}, σ={best_sigma:.2f}, EI={next_ei:.2f}\")\n",
    "print(f\"  Explore–Exploit score: {score:+.2f}\")\n",
    "\n",
    "# run experiment (replace with actual lab call)\n",
    "y_new = run_experiment(np.array(list(next_params.values())), mode='random')\n",
    "print(f\"  Experiment yield: {y_new:.2f}\\n\")\n",
    "\n",
    "# update training set\n",
    "new_x = np.array([[next_params[c] for c in bounds]])  # shape (1, d)\n",
    "X_loop = np.vstack([X_loop, new_x])\n",
    "y_loop = np.append(y_loop, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b02091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88524330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
