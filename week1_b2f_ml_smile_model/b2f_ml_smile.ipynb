{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c860790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- RDKit for molecular fingerprint extraction ---\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def smiles_to_fp(smiles, n_bits=256, radius=2):\n",
    "    mol = Chem.MolFromSmiles(smiles) if pd.notna(smiles) else None\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits, dtype=int)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    arr = np.asarray(fp)\n",
    "    return arr\n",
    "\n",
    "print(smiles_to_fp('CCO').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load raw data ---\n",
    "b2f_mlmodel_df = pd.read_csv('../ylab-ML-MODEL/data/batch2flow_updated.csv', index_col='item')\n",
    "print(\"Columns:\", b2f_mlmodel_df.columns)\n",
    "\n",
    "# --- Manually or automatically identify SMILES columns ending with _B or by chemical column names ---\n",
    "possible_smiles_cols = [col for col in b2f_mlmodel_df.columns if (\n",
    "    col.endswith('_B') or col in ['reagent1', 'reagent2', 'reagent3', 'solvent', 'additive1', 'catalyst']\n",
    ")]\n",
    "# Check actual string type\n",
    "smiles_cols = [col for col in possible_smiles_cols if b2f_mlmodel_df[col].dtype == 'object']\n",
    "print(\"SMILES columns:\", smiles_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convert all SMILES columns to fingerprint matrices and concatenate ---\n",
    "n_bits = 256  # To avoid feature explosion\n",
    "\n",
    "fp_feature_frames = []\n",
    "for col in smiles_cols:\n",
    "    # Compute fingerprint matrix for column\n",
    "    fp_mat = np.stack(b2f_mlmodel_df[col].fillna('').apply(smiles_to_fp, n_bits=n_bits))\n",
    "    fp_df = pd.DataFrame(fp_mat, index=b2f_mlmodel_df.index, columns=[f\"{col}_fp{i}\" for i in range(n_bits)])\n",
    "    fp_feature_frames.append(fp_df)\n",
    "\n",
    "# --- Merge all fingerprints with the original data (excluding original SMILES) ---\n",
    "numeric_df = b2f_mlmodel_df.drop(columns=smiles_cols)\n",
    "merged_df = pd.concat([numeric_df] + fp_feature_frames, axis=1)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a955ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean missing columns, pivot to wide format for ML modeling ---\n",
    "\n",
    "# Keep only numeric columns and F/B for pivot\n",
    "numeric_cols = merged_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "fb = merged_df[['F/B']]\n",
    "numeric_merged_df = pd.concat([fb, merged_df[numeric_cols]], axis=1)\n",
    "\n",
    "# Remove columns with too many missing values\n",
    "missing_frac = numeric_merged_df.isnull().mean()\n",
    "cols_to_drop = missing_frac[missing_frac > 1].index.tolist()\n",
    "df = numeric_merged_df.drop(columns=cols_to_drop).copy()\n",
    "\n",
    "# Assign batch number, reshape to wide format (pivot)\n",
    "df['batch'] = ((df.index + 1) // 2).astype(int)\n",
    "flow_vars = [c.replace('_B', '').replace('_F', '') for c in numeric_cols if not c.startswith('exist_')]\n",
    "df_wide = df.pivot(index='batch', columns='F/B', values=flow_vars)\n",
    "df_wide.columns = [f\"{var}_{fb}\" for var, fb in df_wide.columns]\n",
    "df_wide = df_wide.reset_index()\n",
    "\n",
    "# Reorder columns for ML (all _B, then all _F)\n",
    "f_cols = sorted([c for c in df_wide if c.endswith('_F')])\n",
    "b_cols = sorted([c for c in df_wide if c.endswith('_B')])\n",
    "df_reordered = df_wide[['batch'] + b_cols + f_cols].set_index('batch')\n",
    "df_full = df_reordered.fillna(0)\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add 'exist_' flag columns: 1 if value != 0, else 0 ---\n",
    "all_features = b_cols + f_cols\n",
    "for feat in all_features:\n",
    "    df_full[f\"exist_{feat}\"] = (df_full[feat] != 0).astype(int)\n",
    "\n",
    "# --- Build interleaved columns for ML input ---\n",
    "new_cols = []\n",
    "for feat in all_features:\n",
    "    new_cols.append(feat)\n",
    "    new_cols.append(f\"exist_{feat}\")\n",
    "df_exist = df_full[new_cols].copy()\n",
    "df_exist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. original target variables\n",
    "target_vars = [\n",
    "    'requiv2_F', 'requiv3_F', 'csolv_F', 'addequiv1_F', 'addequiv2_F',\n",
    "    'catequiv1_F', 'catequiv2_F', 'pcequiv_F', 'temp_F', 'time_F'\n",
    "]\n",
    "\n",
    "# 2. setup feature_cols: _B + exist_*_B + fingerprint\n",
    "b_features = [col for col in df_full.columns if col.endswith('_B')]\n",
    "exist_features = [col for col in df_exist.columns if col.startswith('exist_') and col.endswith('_B')]\n",
    "\n",
    "# assume fingerprint column name _fp0/_fp1... as end, eg. fp_cols = [col for col in df_full.columns if col.startswith('smiles_fp')]\n",
    "fp_features = [col for col in df_full.columns if '_fp' in col]\n",
    "feature_cols = list(dict.fromkeys(b_features + exist_features + fp_features))\n",
    "\n",
    "# 3. target variables\n",
    "f_features = target_vars\n",
    "\n",
    "# 4. Build input/output\n",
    "X = df_exist[feature_cols].values\n",
    "y = df_full[f_features].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 5. Standardization\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "\n",
    "# 6. Train MLP\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(128, 512, 256, 128),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,\n",
    "    max_iter=5000,\n",
    "    early_stopping=False,\n",
    "    tol=1e-6,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "mlp.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# 7. Predict and inverse scale, force negative to 0\n",
    "pred_scaled = mlp.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(pred_scaled)\n",
    "y_pred = np.clip(y_pred, 0, None)\n",
    "\n",
    "# 8. Assemble result DataFrame (仅老10个目标)\n",
    "X_test_df = pd.DataFrame(X_test, columns=feature_cols)\n",
    "y_test_df = pd.DataFrame(y_test, columns=f_features)\n",
    "pred_df = pd.DataFrame(y_pred, columns=[f\"predicted_{c}\" for c in f_features])\n",
    "combined_df = pd.concat([X_test_df, y_test_df, pred_df], axis=1)\n",
    "\n",
    "pd.DataFrame(combined_df)\n",
    "\n",
    "# 9. exist_*_B == 0 predicted value need equal 0 must be\n",
    "\n",
    "for fcol in f_features:\n",
    "    pred_col = f'predicted_{fcol}'\n",
    "    combined_df.loc[combined_df[fcol] == 0, pred_col] = 0\n",
    "\n",
    "# 10. Again, ensure no small negatives\n",
    "for fcol in f_features:\n",
    "    pred_col = f'predicted_{fcol}'\n",
    "    if pred_col in combined_df.columns:\n",
    "        combined_df[pred_col] = combined_df[pred_col].clip(lower=0)\n",
    "\n",
    "pd.DataFrame(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Only plot the 10 original variables           \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_plots = len(f_features)\n",
    "n_cols = 5\n",
    "n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(5*n_cols, 5*n_rows))\n",
    "for i, col in enumerate(f_features):\n",
    "    pcd ~/Desktop/ai4sci_demot.subplot(n_rows, n_cols, i+1)\n",
    "    # x: Real, y: Predicted\n",
    "    plt.scatter(combined_df[col], combined_df[f\"predicted_{col}\"], alpha=0.6, edgecolor='k')\n",
    "    min_val = min(combined_df[col].min(), combined_df[f\"predicted_{col}\"].min())\n",
    "    max_val = max(combined_df[col].max(), combined_df[f\"predicted_{col}\"].max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Ideal: y = x')\n",
    "    plt.xlabel('Real Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.title(col)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f94963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
